{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MySQLdb as db\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Connect to Database\n",
    "name = \"DatabaseMain\"\n",
    "con = db.connect(host=\"localhost\", user=\"root\", passwd='', db=name)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ABT - wifi averages into a df\n",
    "sql_avgs = \"\"\"SELECT G.DateTime, W.Room, R.Capacity, T.Module, M.NumReg, W.AvgNumWifiConn, G.PercentageEstimate, G.BinaryEstimate\n",
    "        FROM DatabaseMain.AverageNumWifiConnections W, DatabaseMain.GroundTruth G, DatabaseMain.Rooms R, DatabaseMain.TimeModule T, DatabaseMain.Modules M\n",
    "        WHERE W.Room = G.Room AND W.DateTime = G.DateTime AND W.Room = G.Room AND W.Room = R.Room AND W.Room = T.Room AND R.Room = W.Room AND R.Room = G.Room AND T.Room = G.Room AND T.Room = R.Room AND T.Room =  W.Room AND T.DateTime = G.DateTime AND M.ModuleName = T.Module\n",
    "        ORDER BY W.Room\"\"\"\n",
    "df_avgs = pd.read_sql_query(sql_avgs, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Index DateTime column - want separate day of week and time\n",
    "# so can be separated by category (e.g day of week or time)\n",
    "\n",
    "df_avgs['Day'] = df_avgs['DateTime'].dt.dayofweek\n",
    "df_avgs['Time'] = df_avgs['DateTime'].dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.concat([pd.DataFrame({'Intercept':np.ones(len(df_avgs))}), df_avgs[['AvgNumWifiConn', 'Capacity']],pd.get_dummies(df_avgs['Room'], prefix='Room')], axis=1)\n",
    "y = df_avgs['BinaryEstimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT W.Room, W.AvgNumWifiConn, R.Capacity\n",
    "        FROM DatabaseMain.ExtraAverageNumWifiConnections W, Rooms R\n",
    "        WHERE R.Room=W.Room AND W.DateTime BETWEEN '2016-07-18 09:00:00' AND '2016-07-18 17:00:00' \"\"\"\n",
    "test_data = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT BinaryEstimate, DateTime, Room\n",
    "            FROM GroundTruthExtra\"\"\"\n",
    "test_results = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = pd.concat([pd.DataFrame({'Intercept':np.ones(len(test_data))}), test_data[['AvgNumWifiConn', 'Capacity']],pd.get_dummies(test_data['Room'], prefix='Room')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear Binary:  0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0 \n",
    "for i in range(0,len(predictions)):\n",
    "    if (predictions[i] == test_results['BinaryEstimate'][i]):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy/len(predictions)        \n",
    "print('Accuracy Linear Binary: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PERCENTAGE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JoanMcCarthy/anaconda/envs/project/lib/python3.5/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Add estimate column\n",
    "df_avgs['Estimate'] = df_avgs['Capacity'] * df_avgs['PercentageEstimate']\n",
    "# Handle outliers - replace them with the NumReg\n",
    "df_avgs['Estimate'].loc[df_avgs['Estimate'] > 200] = df_avgs['NumReg']\n",
    "\n",
    "df_avgs['EstimateAsPercent'] = df_avgs['Estimate'] / df_avgs['Capacity']\n",
    "groups = [ '0%', '25%', '50%', '75%', '100%',]\n",
    "bins = [-0.01, 0.00, 0.25, 0.50, 0.75, 1.00]\n",
    "df_avgs['PercentagePred'] = pd.cut(df_avgs['EstimateAsPercent'], bins, labels = groups )\n",
    "df_avgs['PercentageCat'] = df_avgs[['PercentagePred', 'Room']].apply(lambda x: ''.join(x), axis=1)\n",
    "df_avgs = df_avgs.drop(['PercentagePred', 'EstimateAsPercent'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Â Model: avgNumconn, Day, Room, NumReg\n",
    "x = pd.concat([pd.DataFrame({'Intercept':np.ones(len(df_avgs))}), df_avgs[['AvgNumWifiConn', 'NumReg']],pd.get_dummies(df_avgs['Room'], prefix='Room'), pd.get_dummies(df_avgs['Day'], prefix='Day')], axis=1)\n",
    "y = df_avgs['PercentageCat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT W.Room, W.AvgNumWifiConn, W.DateTime\n",
    "        FROM DatabaseMain.ExtraAverageNumWifiConnections W, Rooms R\n",
    "        WHERE R.Room=W.Room AND W.DateTime BETWEEN '2016-07-18 09:00:00' AND '2016-07-18 17:00:00' \"\"\"\n",
    "test_data = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = pd.concat([test_data, pd.DataFrame({'NumReg':np.zeros(len(test_data))})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['Day'] = test_data['DateTime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT PercentageEstimate, DateTime, Room\n",
    "            FROM GroundTruthExtra\"\"\"\n",
    "test_results = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = pd.concat([pd.DataFrame({'Intercept':np.ones(len(test_data))}), test_data[['AvgNumWifiConn', 'NumReg']],pd.get_dummies(test_data['Room'], prefix='Room'), pd.get_dummies(test_data['Day'], prefix='Day')], axis=1)\n",
    "x_test = pd.concat([x_test, pd.DataFrame({'Day_1':np.zeros(len(test_data))}), pd.DataFrame({'Day_2':np.zeros(len(test_data))}), pd.DataFrame({'Day_3':np.zeros(len(test_data))}), pd.DataFrame({'Day_4':np.zeros(len(test_data))})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = [int(predictions[i].split('%')[0])/100 for i in range(0, len(predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear Binary:  0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0 \n",
    "for i in range(0,len(predictions)):\n",
    "    if (predictions[i] == test_results['PercentageEstimate'][i]):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy/len(predictions)        \n",
    "print('Accuracy Linear Binary: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESTIMATE MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUN SECTION 2-4 AGAIN FIRST TO GET ORIGINAL ABTS\n",
    "# Bin results into categories for logistic regression. \n",
    "bins = [-1, 25, 50, 75, 100, 125, 150, 175, 200, 220]\n",
    "groups = [ '0-25', '25-50', '50-75', '75-100', '100-125', '125-150', '150-175', '175-200', '200-220']\n",
    "df_avgs['OccupantEstimate'] = pd.cut(df_avgs['Estimate'], bins, labels = groups )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Â Model: 'AvgNumWifiConn', 'Day', 'Module', 'NumReg', 'Capacity'\n",
    "x = pd.concat([pd.DataFrame({'Intercept':np.ones(len(df_avgs))}), df_avgs[['AvgNumWifiConn', 'NumReg', 'Capacity']],pd.get_dummies(df_avgs['Module'], prefix='Module'), pd.get_dummies(df_avgs['Day'], prefix='Day')], axis=1)\n",
    "y = df_avgs['OccupantEstimate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression().fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT W.AvgNumWifiConn, W.DateTime, R.Capacity\n",
    "        FROM DatabaseMain.ExtraAverageNumWifiConnections W, Rooms R\n",
    "        WHERE R.Room=W.Room AND W.DateTime BETWEEN '2016-07-18 09:00:00' AND '2016-07-18 17:00:00' \"\"\"\n",
    "test_data = pd.read_sql_query(sql, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data['Day'] = test_data['DateTime'].dt.dayofweek\n",
    "test_data = pd.concat([test_data, pd.DataFrame({'Module': 'None', 'NumReg':np.zeros(len(test_data)) })],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sql = \"\"\"SELECT G.PercentageEstimate, G.DateTime, G.Room, R.Capacity\n",
    "            FROM GroundTruthExtra G, Rooms R\n",
    "            WHERE R.Room = G.Room\"\"\"\n",
    "test_results = pd.read_sql_query(sql, con)\n",
    "test_results['Estimate'] = test_results['Capacity'] * test_results['PercentageEstimate']\n",
    "test_results['OccupantEstimate'] = pd.cut(test_results['Estimate'], bins, labels = groups )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_test = pd.concat([pd.DataFrame({'Intercept':np.ones(len(test_data))}), test_data[['AvgNumWifiConn', 'NumReg', 'Capacity']],pd.get_dummies(test_data['Day'], prefix='Day')], axis=1)\n",
    "x_test = pd.concat([x_test, pd.DataFrame({'Day_1':np.zeros(len(test_data))}), pd.DataFrame({'Day_2':np.zeros(len(test_data))}), pd.DataFrame({'Day_3':np.zeros(len(test_data))}), pd.DataFrame({'Day_4':np.zeros(len(test_data))})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(4,len(x.columns)-5):\n",
    "    if x.columns[i] == 'Module_None':\n",
    "        x_test = pd.concat([x_test, pd.DataFrame({x.columns[i]:np.ones(len(test_data))})], axis=1)\n",
    "    else:\n",
    "        x_test = pd.concat([x_test, pd.DataFrame({x.columns[i]:np.zeros(len(test_data))})], axis=1)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = logreg.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear Binary:  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0 \n",
    "for i in range(0,len(predictions)):\n",
    "    if (predictions[i] == test_results['OccupantEstimate'][i]):\n",
    "        accuracy += 1\n",
    "\n",
    "accuracy = accuracy/len(predictions)        \n",
    "print('Accuracy Linear Binary: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "[1] Wirth, R. and Hipp, J., 2000, April. CRISP-DM: Towards a standard process model for data mining. In Proceedings of the 4th international conference on the practical applications of knowledge discovery and data mining (pp. 29-39).\n",
    "\n",
    "[2] Ifrim, G., âLecture8-DataUnderstanding-Stats-Visualisationâ, (COMP47350 Lecture Notes), University College Dublin, 2016\n",
    "\n",
    "[3] Ifrim, G., âLecture12-DataUnderstanding-Correlationâ, (COMP47350 Lecture Notes), University College Dublin, 2016\n",
    "\n",
    "[4] Ifrim, G.,  âLecture10-DataUnderstanding-MotorInsurance-handsonâ, (COMP47350 Lecture Notes), University College Dublin, 2016\n",
    "\n",
    "[5] Ifrim, G., âLecture15-Regression-LinearRegression-Interpretation-updatedâ, (COMP47350 Lecture Notes), University College Dublin, 2016\n",
    "\n",
    "[6] Ifrim, G., âLecture16-LinearRegression-handson, (COMP47350 Lecture Notes)â, University College Dublin, 2016\n",
    "\n",
    "[7] Ifrim, G., âLecture19-ModelEvaluation-ExperimentDesign, (COMP47350 Lecture Notes)â, University College Dublin, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
