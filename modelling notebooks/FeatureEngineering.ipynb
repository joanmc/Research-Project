{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import MySQLdb as db\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/questions/464864/python-code-to-pick-out-all-possible-combinations-from-a-list\n",
    "import itertools\n",
    "\n",
    "# All possible combinations of features\n",
    "subsets = []\n",
    "features = ['Day', 'Time', 'Module', 'Room', 'NumReg', 'Capacity']\n",
    "for L in range(1, len(features)+1):\n",
    "    for subset in itertools.combinations(features, L):\n",
    "        subsets.append(subset)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Connect to Database\n",
    "name = \"DatabaseMain\"\n",
    "con = db.connect(host=\"localhost\", user=\"root\", passwd='', db=name)\n",
    "cursor = con.cursor()\n",
    "\n",
    "# ABT - all wifi data into a df\n",
    "sql = \"\"\"SELECT G.DateTime, W.Room, R.Capacity, T.Module, M.NumReg, W.Associated, G.PercentageEstimate, G.BinaryEstimate\n",
    "        FROM DatabaseMain.WifiLogData W, DatabaseMain.GroundTruth G, DatabaseMain.Rooms R, DatabaseMain.TimeModule T, DatabaseMain.Modules M\n",
    "        WHERE W.Room = G.Room AND W.DateTime BETWEEN G.DateTime AND DATE_ADD(G.DateTime, INTERVAL 1 HOUR) AND R.Room = W.Room AND R.Room = G.Room AND T.Room = G.Room AND T.Room = R.Room AND T.Room =  W.Room AND T.DateTime = G.DateTime AND M.ModuleName = T.Module\"\"\"\n",
    "df = pd.read_sql_query(sql, con)\n",
    "\n",
    "# ABT - wifi averages into a df\n",
    "sql_avgs = \"\"\"SELECT G.DateTime, W.Room, R.Capacity, T.Module, M.NumReg, W.AvgNumWifiConn, G.PercentageEstimate, G.BinaryEstimate\n",
    "        FROM DatabaseMain.AverageNumWifiConnections W, DatabaseMain.GroundTruth G, DatabaseMain.Rooms R, DatabaseMain.TimeModule T, DatabaseMain.Modules M\n",
    "        WHERE W.Room = G.Room AND W.DateTime = G.DateTime AND W.Room = G.Room AND W.Room = R.Room AND W.Room = T.Room AND R.Room = W.Room AND R.Room = G.Room AND T.Room = G.Room AND T.Room = R.Room AND T.Room =  W.Room AND T.DateTime = G.DateTime AND M.ModuleName = T.Module\n",
    "        ORDER BY W.Room\"\"\"\n",
    "df_avgs = pd.read_sql_query(sql_avgs, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime              datetime64[ns]\n",
       "Room                        category\n",
       "Capacity                       int64\n",
       "Module                      category\n",
       "NumReg                         int64\n",
       "Associated                     int64\n",
       "PercentageEstimate           float64\n",
       "BinaryEstimate                 int64\n",
       "Day                         category\n",
       "Time                        category\n",
       "dtype: object"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index DateTime column - want separate day of week and time\n",
    "# so can be separated by category (e.g day of week or time)\n",
    "\n",
    "df['Day'] = df['DateTime'].dt.dayofweek\n",
    "df['Time'] = df['DateTime'].dt.time\n",
    "\n",
    "df_avgs['Day'] = df_avgs['DateTime'].dt.dayofweek\n",
    "df_avgs['Time'] = df_avgs['DateTime'].dt.time\n",
    "\n",
    "categories = ['Day', 'Time', 'Module', 'Room']\n",
    "for cat in categories:\n",
    "    df[cat] = df[cat].astype('category')\n",
    "    df_avgs[cat] = df_avgs[cat].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find best model: can only use tues-fri wk1, mon-fri wk2, 9-5\n",
    "def FeatureEngineering(df, target, wifiData):\n",
    "    results = pd.DataFrame(columns=['Features', 'CrossValScore', 'NullAccuracy'])\n",
    "    intercept = pd.DataFrame({'Intercept':np.ones(len(df))})\n",
    "    y = df[target]\n",
    "    \n",
    "    for ind, sub in enumerate(subsets): \n",
    "        x = pd.concat([intercept, df[wifiData]], axis=1)\n",
    "        features = [wifiData]\n",
    "        for s in sub:\n",
    "            features.append(s)\n",
    "            if pd.core.common.is_categorical_dtype(df[s]):\n",
    "                x = pd.concat([x, pd.get_dummies(df[s], prefix=s)], axis=1)\n",
    "            else:\n",
    "                x = pd.concat([x, df[s]], axis=1)\n",
    "        results.loc[ind] = [features, cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv = 10).mean(), cross_val_score(DummyClassifier(strategy='most_frequent'), x, y, scoring='accuracy', cv = 10).mean()]\n",
    "    return results\n",
    "\n",
    "def PredictOccupancy(results, df, target, wifiData):\n",
    "    features = results['Features'][results['CrossValScore'].idxmax()]\n",
    "    x = pd.DataFrame(pd.concat([pd.DataFrame({'Intercept':np.ones(len(df))})], axis=1))\n",
    "    y = df[target]\n",
    "\n",
    "    for feat in features:\n",
    "        if pd.core.common.is_categorical_dtype(df[feat]):\n",
    "            x = pd.concat([x, pd.get_dummies(df[feat], prefix=feat)], axis=1)\n",
    "        else:\n",
    "            x = pd.concat([x, df[feat]], axis=1)\n",
    "  \n",
    "    logreg = LogisticRegression().fit(x, y)\n",
    "    predictions = pd.DataFrame(logreg.predict(x), columns=[\"Predictions\"])\n",
    "    return pd.concat([df['DateTime'], df['Room'], predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = 'BinaryEstimate'\n",
    "wifiData = 'Associated'\n",
    "wifiDataAvgs = 'AvgNumWifiConn'\n",
    "\n",
    "# FeatureEngineering returns a df with all possible models,\n",
    "# df contains colums with features used in the model, the cross validation score and the null_accuracy cross validation score\n",
    "res = FeatureEngineering(df, target, wifiData)\n",
    "res_avgs = FeatureEngineering(df_avgs, target, wifiDataAvgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All wifi data:  0.799403984064\n",
      "Averages:  0.852077922078\n",
      "Features in best model (all wifi data):  ['Associated', 'Time', 'Room', 'Capacity']\n",
      "Features in best model (averages):  ['AvgNumWifiConn', 'Room', 'Capacity']\n"
     ]
    }
   ],
   "source": [
    "# Find best model (highest cross val score)\n",
    "print(\"All wifi data: \", res['CrossValScore'].max())\n",
    "print(\"Averages: \", res_avgs['CrossValScore'].max())\n",
    "print(\"Features in best model (all wifi data): \", res['Features'][res['CrossValScore'].idxmax()] )\n",
    "print(\"Features in best model (averages): \", res_avgs['Features'][res_avgs['CrossValScore'].idxmax()] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions for the best model\n",
    "predictions = PredictOccupancy(res, df, target, wifiData)\n",
    "predictions_avgs = PredictOccupancy(res_avgs, df_avgs, target, wifiDataAvgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               DateTime   Room  Estimate\n",
      "0   2015-11-03 09:00:00  B-002       0.0\n",
      "1   2015-11-03 10:00:00  B-002       1.0\n",
      "2   2015-11-03 11:00:00  B-002       1.0\n",
      "3   2015-11-03 12:00:00  B-002       1.0\n",
      "4   2015-11-03 13:00:00  B-002       0.0\n",
      "5   2015-11-03 14:00:00  B-002       1.0\n",
      "6   2015-11-03 15:00:00  B-002       1.0\n",
      "7   2015-11-03 16:00:00  B-002       1.0\n",
      "8   2015-11-04 09:00:00  B-002       0.0\n",
      "9   2015-11-04 10:00:00  B-002       1.0\n",
      "10  2015-11-04 11:00:00  B-002       1.0\n",
      "11  2015-11-04 12:00:00  B-002       1.0\n",
      "12  2015-11-04 13:00:00  B-002       1.0\n",
      "13  2015-11-04 14:00:00  B-002       1.0\n",
      "14  2015-11-04 15:00:00  B-002       1.0\n",
      "15  2015-11-04 16:00:00  B-002       1.0\n",
      "16  2015-11-05 09:00:00  B-002       0.0\n",
      "17  2015-11-05 10:00:00  B-002       1.0\n",
      "18  2015-11-05 11:00:00  B-002       1.0\n",
      "19  2015-11-05 12:00:00  B-002       1.0\n",
      "20  2015-11-05 13:00:00  B-002       0.0\n",
      "21  2015-11-05 14:00:00  B-002       1.0\n",
      "22  2015-11-05 15:00:00  B-002       1.0\n",
      "23  2015-11-05 16:00:00  B-002       1.0\n",
      "24  2015-11-06 09:00:00  B-002       0.0\n",
      "25  2015-11-06 10:00:00  B-002       0.0\n",
      "26  2015-11-06 11:00:00  B-002       1.0\n",
      "27  2015-11-06 12:00:00  B-002       1.0\n",
      "28  2015-11-06 13:00:00  B-002       0.0\n",
      "29  2015-11-06 14:00:00  B-002       1.0\n",
      "..                  ...    ...       ...\n",
      "186 2015-11-10 11:00:00  B-004       1.0\n",
      "187 2015-11-10 12:00:00  B-004       1.0\n",
      "188 2015-11-10 13:00:00  B-004       1.0\n",
      "189 2015-11-10 14:00:00  B-004       1.0\n",
      "190 2015-11-10 15:00:00  B-004       1.0\n",
      "191 2015-11-10 16:00:00  B-004       0.0\n",
      "192 2015-11-11 09:00:00  B-004       0.0\n",
      "193 2015-11-11 10:00:00  B-004       0.0\n",
      "194 2015-11-11 11:00:00  B-004       1.0\n",
      "195 2015-11-11 12:00:00  B-004       1.0\n",
      "196 2015-11-11 13:00:00  B-004       0.0\n",
      "197 2015-11-11 14:00:00  B-004       0.0\n",
      "198 2015-11-11 15:00:00  B-004       1.0\n",
      "199 2015-11-11 16:00:00  B-004       0.0\n",
      "200 2015-11-12 09:00:00  B-004       1.0\n",
      "201 2015-11-12 10:00:00  B-004       1.0\n",
      "202 2015-11-12 11:00:00  B-004       1.0\n",
      "203 2015-11-12 12:00:00  B-004       1.0\n",
      "204 2015-11-12 13:00:00  B-004       1.0\n",
      "205 2015-11-12 14:00:00  B-004       1.0\n",
      "206 2015-11-12 15:00:00  B-004       0.0\n",
      "207 2015-11-12 16:00:00  B-004       1.0\n",
      "208 2015-11-13 09:00:00  B-004       0.0\n",
      "209 2015-11-13 10:00:00  B-004       1.0\n",
      "210 2015-11-13 11:00:00  B-004       1.0\n",
      "211 2015-11-13 12:00:00  B-004       1.0\n",
      "212 2015-11-13 13:00:00  B-004       0.0\n",
      "213 2015-11-13 14:00:00  B-004       1.0\n",
      "214 2015-11-13 15:00:00  B-004       0.0\n",
      "215 2015-11-13 16:00:00  B-004       0.0\n",
      "\n",
      "[216 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# want only one prediction for each hour \n",
    "# all wifi data predictions predict for every five minutes of the hour\n",
    "# take most common result of each hour as final prediction\n",
    "\n",
    "# list of all datetimes\n",
    "DateTimes = df['DateTime'].unique()\n",
    "# list of all rooms\n",
    "Rooms = df['Room'].unique()\n",
    "\n",
    "# dataframes to hold results\n",
    "final_predictions = pd.DataFrame(columns=['DateTime', 'Room', 'Estimate'])\n",
    "room = pd.DataFrame(columns=['DateTime', 'Room', 'Estimate'])\n",
    "\n",
    "# iterate through each datetime for eech room\n",
    "for r in Rooms:\n",
    "    for ind, dt in enumerate(DateTimes):\n",
    "        # get all the predictions for particular hour for particular room\n",
    "        # http://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas\n",
    "        group = predictions['Predictions'].loc[((predictions['DateTime'] == dt) & (predictions['Room'] == r))]\n",
    "    #     print(group['Predictions'].value_counts())\n",
    "    #     print('MAX:', group['Predictions'].value_counts().idxmax())\n",
    "        # add datetime, room and most common prediction for the hour to a dataframe\n",
    "        # most frequent value: http://stackoverflow.com/questions/15138973/how-to-get-the-number-of-the-most-frequent-value-in-a-column\n",
    "        room.loc[ind] = [dt, r, group.value_counts().idxmax()]\n",
    "    # add dataframe (room) containing final predictions for a certain room to the final_predictions df\n",
    "    # need to do this becuase 'ind' gets reset for each room so will overwrite rows already in dataframe 'room'\n",
    "    final_predictions = final_predictions.append(room, ignore_index=True)\n",
    "\n",
    "print(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JoanMcCarthy/anaconda/envs/project/lib/python3.5/site-packages/pandas/core/generic.py:1165: FutureWarning: The 'mysql' flavor with DBAPI connection is deprecated and will be removed in future versions. MySQL will be further supported with SQLAlchemy connectables.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "# Add results to table in database\n",
    "name = 'DatabaseMain'\n",
    "conn = db.connect(host = \"localhost\", user = \"root\", passwd =\"\", db=name)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "final_predictions.to_sql(con=con, name='BinaryPredictions', if_exists='replace', flavor='mysql')\n",
    "predictions_avgs.to_sql(con=con, name='BinaryPredictionsAvgs', if_exists='replace', flavor='mysql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
